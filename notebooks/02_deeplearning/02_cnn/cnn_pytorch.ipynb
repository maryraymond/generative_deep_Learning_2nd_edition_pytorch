{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèû Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an **unofficial PyTorch implementation** of the excellent [Keras example](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/blob/main/notebooks/02_deeplearning/02_cnn/cnn.ipynb) for Convolutional neural network, originally created by David Foster as part of the companion code for the excellent book [Generative Deep Learning, 2nd Edition](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The original code is available [here](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition) and is licensed under the Apache License 2.0._\n",
    "_This implementation is distributed under the Apache License 2.0. See the LICENSE file for details._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own convolutional neural network (CNN) on the CIFAR dataset using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the working directory and the current notebook directory\n",
    "working_dir = os.getcwd()\n",
    "exp_dir = os.path.join(working_dir, \"notebooks/02_deeplearning/02_cnn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from notebooks.utils import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = working_dir + \"/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the labels here will not be one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for the data (e.g., normalization, conversion to tensors)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# the pytorch loss fucntion uses the integer lables directly no need to convert them to one hot encoding\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, \n",
    "                                        transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, \n",
    "                                       transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first batch of images\n",
    "dataiter = iter(trainloader)\n",
    "images, lables = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(images[:10])\n",
    "print(lables[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the model <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # define the layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, \n",
    "                               stride=1, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        p = self._get_padding_size(32,  2, 3)\n",
    "        print(p)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, \n",
    "                               stride=2, padding=p)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, \n",
    "                               stride=1, padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        p = self._get_padding_size(16,  2, 3)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,\n",
    "                               stride=2, padding=p)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.fc1 = nn.Linear(8*8*64, 128)\n",
    "        self.bn5 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.fc2 = nn.Linear(128, NUM_CLASSES)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_padding_size(input_w, stride, kernal_size):\n",
    "        p = ((input_w /2) - 1) * stride\n",
    "        p = (p - input_w) + kernal_size\n",
    "        p = math.ceil(p/2)\n",
    "\n",
    "        return p\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        # flatten the input\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn5(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # x = torch.softmax(x, dim=1)\n",
    "        # CrossEntropyLoss combins the softmax with the loss function so no need to add softmax layer to the model\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel().to(device)\n",
    "print(model.state_dict().keys())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (1, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# CrossEntropyLoss combome the softmax with the loss function so no need to add softmax layer to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optmizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dataloader, optimizer, loss_fn, epochs=10):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    # loop over the number of epoch\n",
    "    for i in range(epochs):\n",
    "        #  set the model for training\n",
    "        model.train()\n",
    "        # loop over the dataloader to get all the data\n",
    "        running_loss = 0.0\n",
    "        num_samples = 0\n",
    "        correct = 0\n",
    "        for images, labels in train_dataloader:\n",
    "            #  zero the gradiants of the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            # move the training data to the same device as the model\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Predict the lables\n",
    "            predictions = model(images)\n",
    "            # calculate the loss\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            # calcualte the gradients for the loss\n",
    "            loss.backward()\n",
    "            # updat the weights using the optimizer\n",
    "            optimizer.step()\n",
    "            # accumilate the loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calcualte the accuracy\n",
    "            _,pred_lable = torch.max(predictions, 1)\n",
    "            # _, corr_label = torch.max(labels, 1)\n",
    "\n",
    "            num_samples += labels.size(0)\n",
    "            correct += (pred_lable==labels).sum().item()\n",
    "        \n",
    "        print( f\"Epoch {i+1} / {epochs}: loss= {running_loss/len(train_dataloader):.4f}, accuracy= {correct/num_samples:.4f}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, trainloader, optimizer, loss_fn, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation <a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model, dataloader, loss_fn, device):\n",
    "    # set the model to eval mode\n",
    "    model.eval()\n",
    "    corr_predictions = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "    # disable the gradiants calculations\n",
    "    with torch.no_grad():\n",
    "        # loop to load all data\n",
    "        for images, lables in dataloader:\n",
    "            images, lables = images.to(device), lables.to(device)\n",
    "            # use the model to predict the labels\n",
    "            outputs = model(images)\n",
    "            # calcaulte the loss\n",
    "            loss = loss_fn(outputs, lables)\n",
    "            total_loss += loss\n",
    "\n",
    "            # get the highest predicted values\n",
    "            _, pred_lables = torch.max(outputs, 1)\n",
    "            # _, corr_lables = torch.max(lables, 1)\n",
    "\n",
    "            corr_predictions += (pred_lables==lables).sum().item()\n",
    "            total += lables.size(0)\n",
    "        \n",
    "        val_loss = total_loss / len(dataloader)\n",
    "        val_acc = corr_predictions / total\n",
    "    \n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = evaluate(model, testloader, loss_fn, device)\n",
    "print(f\"validation loss: {val_loss}, validation_acc: {val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try indvidual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array(\n",
    "    [\n",
    "        \"airplane\",\n",
    "        \"automobile\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, lables = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(images.to(device))\n",
    "_, pred_index = torch.max(output.detach().cpu(), 1)\n",
    "predicted_class = CLASSES[pred_index]\n",
    "\n",
    "# _, index = torch.max(lables, 1)\n",
    "gt_classes = CLASSES[lables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(images)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = images[idx].permute(1,2,0).numpy()\n",
    "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.35,\n",
    "        \"pred = \" + str(predicted_class[idx]),\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.7,\n",
    "        \"act = \" + str(gt_classes[idx]),\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
