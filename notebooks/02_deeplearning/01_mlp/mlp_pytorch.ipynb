{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ‘€ Multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"/home/mary/work/repos/generative_deep_Learning_2nd_edition_pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to the notebooks folder\n",
    "notebooks_path = os.path.abspath(working_dir)\n",
    "if notebooks_path not in sys.path:\n",
    "    sys.path.append(notebooks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "# from torchinfo import summary\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from notebooks.utils import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the Data <a name=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = working_dir + \"/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Manual method <a name=\"manual\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method we will try to memic as much as possible the steps done to load the Cifar 10 data in keras, you can skip this to the pytorch style if you are not interested in this method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True)\n",
    "print(type(trainset))\n",
    "print(trainset[0])\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will define a transform to convert to tensor, this ToTensor transform will also internally scale the color channel to 0-1 and permute the image shape to be [C, H, W], if we want a tranformer that only convert to tensor or numpy we can implment a custom one using Lambda.\n",
    "The list of available transfors could be found here (https://pytorch.org/vision/0.9/transforms.html#functional-transforms)\n",
    "- Note: Pytorch uses a channel first format (i.e [C, H, W]) where as tensor flow uses channel-last format (i.e [H, W, C]), the channel first format align with PyTorch's conventions and optimize memory layout for efficient computation, especially on GPUs. this format is optimized for PyTorchâ€™s back-end libraries (e.g., cuDNN) and GPU acceleration. This arrangement allows faster access to data during operations on individual channels, which is common in convolutional neural networks (CNNs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.stack([transform(data_item[0]) for data_item in trainset], dim=0)\n",
    "x_test = torch.stack([transform(data_item[0]) for data_item in testset], dim=0)\n",
    "\n",
    "y_train = torch.as_tensor([data_item[1] for data_item in trainset])\n",
    "y_test = torch.as_tensor([data_item[1] for data_item in testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lables to one hot encoding\n",
    "y_train = F.one_hot(y_train, num_classes=NUM_CLASSES)\n",
    "y_test = F.one_hot(y_test, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_train[:10])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we have different options on how to use x_train and y_train to train the model\n",
    "- We can use them as tensors in the training loop and handle the batches using tensor slicing\n",
    "- We can use TensorDataset to convert the training samples and lables into a pytorch dataset (which is re-inventing the wheel since the loaded trainset was already a TensorDataset) and then use DataLoader to get a dataloader that will also handle the batch size, and can have a number of workers for large datasets\n",
    "- We can implment our own custom DataSet and DataLoader by inherting those clases (if we want to do something expecial)\n",
    "\n",
    "Here we will use the second option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pytorch method <a name=\"pytorch\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the labels here will not be one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations for the data (e.g., normalization, conversion to tensors)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def one_hot_encode(label):\n",
    "    return F.one_hot(torch.tensor(label), num_classes=NUM_CLASSES).float()\n",
    "\n",
    "# Download and load the CIFAR-10 training and test datasets\n",
    "# trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, \n",
    "#                                         transform=transform, target_transform=one_hot_encode)\n",
    "\n",
    "# the pytorch loss fucntion uses the integer lables directly no need to convert them to one hot encoding\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, \n",
    "                                        transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, \n",
    "#                                        transform=transform, target_transform=one_hot_encode)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, \n",
    "                                       transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first batch of images\n",
    "dataiter = iter(trainloader)\n",
    "images, lables = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(images)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(images[:10])\n",
    "print(lables[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the model <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 without including the activations in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # define the layers\n",
    "        self.input = nn.Linear(32*32*3, 200)\n",
    "        self.fc1 = nn.Linear(200, 150)\n",
    "        self.fc2 = nn.Linear(150, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # flatten the input\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.input(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = torch.softmax(x, dim=1)\n",
    "        # CrossEntropyLoss combome the softmax with the loss function so no need to add softmax layer to the model\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPModel_1().to(device)\n",
    "print(model.state_dict().keys())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 with including the activations in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # define the layers\n",
    "        self.input = nn.Linear(32*32*3, 200)\n",
    "        self.activ_1 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(200, 150)\n",
    "        self.activ_2 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(150, NUM_CLASSES)\n",
    "        self.activ_3 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # flatten the input\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.input(x)\n",
    "        x = self.activ_1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activ_2(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.activ_3(x)\n",
    "        # CrossEntropyLoss combome the softmax with the loss function so no need to add softmax layer to the model\n",
    "        # If softmax is used then we can use the NLLLoss (Negative Log Likelihood Loss)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPModel_2().to(device)\n",
    "print(model.state_dict().keys())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# CrossEntropyLoss combome the softmax with the loss function so no need to add softmax layer to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optmizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dataloader, optimizer, loss_fn, epochs=10):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    # loop over the number of epoch\n",
    "    for i in range(epochs):\n",
    "        #  set the model for training\n",
    "        model.train()\n",
    "        # loop over the dataloader to get all the data\n",
    "        running_loss = 0.0\n",
    "        num_samples = 0\n",
    "        correct = 0\n",
    "        for images, labels in train_dataloader:\n",
    "            #  zero the gradiants of the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            # move the training data to the same device as the model\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Predict the lables\n",
    "            predictions = model(images)\n",
    "            # calculate the loss\n",
    "            loss = loss_fn(predictions, labels)\n",
    "            # calcualte the gradients for the loss\n",
    "            loss.backward()\n",
    "            # updat the weights using the optimizer\n",
    "            optimizer.step()\n",
    "            # accumilate the loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calcualte the accuracy\n",
    "            _,pred_lable = torch.max(predictions, 1)\n",
    "            # _, corr_label = torch.max(labels, 1)\n",
    "\n",
    "            num_samples += labels.size(0)\n",
    "            correct += (pred_lable==labels).sum().item()\n",
    "        \n",
    "        print( f\"Epoch {i} / {epochs}: loss= {running_loss/len(train_dataloader):.4f}, accuracy= {correct/num_samples:.4f}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, trainloader, optimizer, loss_fn, num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation <a name=\"evaluate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate (model, dataloader, loss_fn, device):\n",
    "    # set the model to eval mode\n",
    "    model.eval()\n",
    "    corr_predictions = 0\n",
    "    total = 0\n",
    "    total_loss = 0.0\n",
    "    # disable the gradiants calculations\n",
    "    with torch.no_grad():\n",
    "        # loop to load all data\n",
    "        for images, lables in dataloader:\n",
    "            images, lables = images.to(device), lables.to(device)\n",
    "            # use the model to predict the labels\n",
    "            outputs = model(images)\n",
    "            # calcaulte the loss\n",
    "            loss = loss_fn(outputs, lables)\n",
    "            total_loss += loss\n",
    "\n",
    "            # get the highest predicted values\n",
    "            _, pred_lables = torch.max(outputs, 1)\n",
    "            # _, corr_lables = torch.max(lables, 1)\n",
    "\n",
    "            corr_predictions += (pred_lables==lables).sum().item()\n",
    "            total += lables.size(0)\n",
    "        \n",
    "        val_loss = total_loss / len(dataloader)\n",
    "        val_acc = corr_predictions / total\n",
    "    \n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = evaluate(model, testloader, loss_fn, device)\n",
    "print(f\"validation loss: {val_loss}, validation_acc: {val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try indvidual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array(\n",
    "    [\n",
    "        \"airplane\",\n",
    "        \"automobile\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, lables = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(images.to(device))\n",
    "_, pred_index = torch.max(output.detach().cpu(), 1)\n",
    "predicted_class = CLASSES[pred_index]\n",
    "\n",
    "# _, index = torch.max(lables, 1)\n",
    "gt_classes = CLASSES[lables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_to_show = 10\n",
    "indices = np.random.choice(range(len(images)), n_to_show)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = images[idx].permute(1,2,0).numpy()\n",
    "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
    "    ax.axis(\"off\")\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.35,\n",
    "        \"pred = \" + str(predicted_class[idx]),\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.7,\n",
    "        \"act = \" + str(gt_classes[idx]),\n",
    "        fontsize=10,\n",
    "        ha=\"center\",\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
